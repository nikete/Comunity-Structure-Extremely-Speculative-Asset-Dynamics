Our baseline model only incorporates the user characteristics that are easily observable from their activity on the forum before the announcement: the number of posts made, the number of threads initiated, the time since first post on the forums (seniority), the number of unique users responded to (out-degree) and the number of unique users from whom a response is received (in-degree).
\textcolor{red}{These network measures are possible for any generic discussion, we introduce two further sets of variables to enrich our models that rely on domain knowledge of the underlying assets: Satoshi network measures, and nontrivialness as defined in section \ref{data_nikete}.}

We estimate the support of our model by regularized least squares using a combination of L1 and L2 norm, with their parameters set by 5-fold cross validation  (ElasticNet implementation in \cite{scikit-learn}) . 
We then estimate an OLS model over the support of the variables and calculate White robust standard errors, which allow us to examine the model coefficients and their standard errors. 
%Disclaimer that the regularization might make them not match (TODO: add set with normal SE that is estimated with the regularization, in results compare the coefficients) 
To evaluate nonlinearities and interactions in the model, we fit a gradient boosted machine and cross validate its hyper parameters, both on the full support and the OLS selected subset. 

The initial analysis pipeline and debugging, hyper-parameter setting was done using only the initial 270 of the eventual 560 in the sample.
\textcolor{red}{The full set of samples used for these estimates were selected before writing the results section, and no adjustments were made to hyper-parameters or methods after this point.}
